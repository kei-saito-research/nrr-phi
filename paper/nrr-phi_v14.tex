\documentclass[11pt,a4paper]{article}

%==============================================================================
% PREAMBLE
%==============================================================================
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{graphicx}
\usepackage[colorlinks=true,linkcolor=blue,citecolor=blue,urlcolor=blue]{hyperref}
\usepackage[numbers]{natbib}
\usepackage{geometry}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{xcolor}

\geometry{
  left=2.5cm,
  right=2.5cm,
  top=2.5cm,
  bottom=2.5cm
}

% Theorem environments
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{remark}{Remark}
\newtheorem{principle}{Principle}

%==============================================================================
% TITLE AND AUTHOR
%==============================================================================
\title{\textbf{NRR-Phi: Text-to-State Mapping for Ambiguity Preservation in LLM Inference}}

\author{
  Kei Saito\thanks{ORCID: 0009-0006-4715-9176} \\
  Independent Researcher, Japan \\
  \texttt{kei.saito.research@gmail.com}
}

\date{February 2026 \\[0.5em]
\textit{Part of the Non-Resolution Reasoning (NRR) research program.}}

\begin{document}

\maketitle

\begin{center}
\textcopyright\ 2026 Kei Saito.
Licensed under CC BY 4.0.\\
\url{https://creativecommons.org/licenses/by/4.0/}
\end{center}

%==============================================================================
% ABSTRACT
%==============================================================================
\begin{abstract}
Large language models exhibit a systematic tendency toward \textit{early semantic commitment}: 
given ambiguous input, they collapse multiple valid interpretations into a single response 
before sufficient context is available. This premature collapse discards information that 
may prove essential as dialogue evolves.

We present a formal framework for \textit{text-to-state mapping} ($\phi: \mathcal{T} \to \mathcal{S}$) 
that transforms natural language into a non-collapsing state space where multiple interpretations 
coexist. The mapping decomposes into three stages: conflict detection, interpretation extraction, 
and state construction. We instantiate $\phi$ with a hybrid extraction pipeline that combines 
rule-based segmentation for explicit conflict markers (adversative conjunctions, hedging expressions) 
with LLM-based enumeration of implicit ambiguity (epistemic, lexical, structural).

On a test set of 68 ambiguous sentences, the resulting states preserve interpretive multiplicity: 
using hybrid extraction we obtain mean state entropy $H = 1.087$ bits across ambiguity categories, 
compared to $H = 0$ for collapse-based baselines that commit to a single interpretation. 
We additionally instantiate the rule-based conflict detector for Japanese markers 
(\textit{kedo}, \textit{kamoshirenai}, etc.) to illustrate cross-lingual portability of the 
conflict detection stage. This framework extends Non-Resolution Reasoning (NRR) by providing 
the missing algorithmic bridge between text and the NRR state space, enabling architectural 
collapse deferment in LLM inference. Design principles for state-to-state transformations 
are detailed in Appendix~\ref{app:operators}, with empirical validation on 580 test cases 
(180 single states, 200 contradictory pairs, 200 temporal pairs) demonstrating 
0\% collapse for principle-satisfying operators versus up to 17.8\% for violating operators.

\textbf{Implementation}: A reference implementation accompanying this work 
is available at \url{https://github.com/kei-saito-research/nrr-phi}.
\end{abstract}

\noindent\textbf{Keywords:} text-to-state mapping, non-resolution reasoning, collapse deferment, 
ambiguity preservation, LLM inference architecture

%==============================================================================
% SECTION 1: INTRODUCTION
%==============================================================================
\section{Introduction}
\label{sec:intro}

\subsection{The Early Semantic Commit Problem}

Large language models (LLMs) have achieved remarkable capabilities in natural language 
understanding and generation. However, these systems share a fundamental architectural 
characteristic: they commit to interpretations early in the inference process, often 
before sufficient context is available to disambiguate.

Consider the input: ``I want to quit my job, but I also don't want to quit.'' 
A standard LLM must produce a response, which requires committing to an interpretation 
of this ambivalent statement. Typical responses either:
\begin{itemize}
    \item Select one pole of the ambivalence as primary (``It sounds like you're leaning toward staying...'')
    \item Reframe the ambivalence as a problem requiring resolution (``Let's make a pros and cons list...'')
    \item Request clarification (``Which feeling is stronger?'')
\end{itemize}

Each of these responses presupposes that the ambivalence \textit{should} be resolved. 
The system cannot maintain both interpretations as valid, coexisting states.

This \textit{early semantic commit} pattern stems from architectural choices embedded 
in standard LLM design:

\paragraph{Softmax Normalization.}
Attention mechanisms use softmax to produce probability distributions that sum to unity, 
forcing interpretations to compete for probability mass rather than coexist independently.

\paragraph{Autoregressive Generation.}
Each token generation step commits irrevocably to a single choice. Uncertainty must be 
resolved \textit{before} output, not deferred.

\paragraph{Training Objectives.}
Cross-entropy loss rewards convergence toward ground-truth tokens, treating maintained 
ambiguity as prediction error rather than valid epistemic state.

\subsection{Non-Resolution Reasoning}

Non-Resolution Reasoning (NRR) \cite{saito2025nrr} offers an alternative paradigm that 
treats ambiguity preservation as a valid computational mode. NRR introduced the state 
space $\mathcal{S} = \{(v_i, c_i, w_i)\}$ where multiple interpretations coexist with 
independent activation weights, and demonstrated that ``NRR-lite'' 
implementations ($k{=}2$ separate embeddings with context gate) maintain high entropy 
($H = 0.91$ bits, near-maximum $1.0$) at ambiguous turns while baseline 
models collapse ($H = 0.15$ bits).

However, a critical component remained undefined: \textbf{how does text become state?} 
The mapping $\phi: \mathcal{T} \to \mathcal{S}$ that transforms natural language input 
into the NRR state space was described conceptually but not algorithmically specified.

\subsection{Contributions}

This paper provides the missing algorithmic bridge. Our contributions are:

\begin{enumerate}
    \item \textbf{Formal Definition of $\phi$}: We define the text-to-state mapping as a 
          composition of three stages: conflict detection, interpretation extraction, 
          and state construction.
    
    \item \textbf{Hybrid Extraction Algorithm}: We combine rule-based segmentation 
          (for explicit conflict markers) with LLM-based enumeration (for implicit 
          ambiguity), providing both reproducibility and coverage.
    
    \item \textbf{Experimental Validation}: We evaluate on 68 ambiguous sentences 
          using three LLMs (ChatGPT, Gemini, Claude), demonstrating consistent entropy 
          preservation ($H = 1.087$) across ambiguity categories.
    
    \item \textbf{Cross-Lingual Portability}: We instantiate the rule-based conflict 
          detector for Japanese markers, demonstrating that the framework is not 
          tied to a single language.
\end{enumerate}

\subsection{Paper Organization}

Section~\ref{sec:related} reviews related work on uncertainty in LLM inference. 
Section~\ref{sec:framework} presents the formal framework for text-to-state mapping. 
Section~\ref{sec:algorithm} provides algorithms and implementation details. 
Section~\ref{sec:experiments} reports experimental results. 
Section~\ref{sec:application} briefly illustrates application to psychological support contexts. 
Section~\ref{sec:discussion} discusses limitations and future work. 
Section~\ref{sec:conclusion} concludes. 
Appendix~\ref{app:operators} details the design principles and definitions of 
the eight NRR operators that transform states while preserving non-collapse.

%==============================================================================
% SECTION 2: RELATED WORK
%==============================================================================
\section{Related Work}
\label{sec:related}

\subsection{Uncertainty in LLM Inference}

Uncertainty quantification in neural networks has received substantial attention 
\cite{gal2016dropout, lakshminarayanan2017simple}. For LLMs specifically, calibration 
studies examine whether model confidence aligns with accuracy \cite{kadavath2022language}. 
However, these approaches focus on \textit{measuring} uncertainty rather than 
\textit{preserving} it architecturally.

Epistemic uncertainty (model uncertainty) and aleatoric uncertainty (data uncertainty) 
are typically distinguished \cite{hullermeier2021aleatoric}. Our framework addresses a 
different dimension: \textit{interpretive multiplicity}, where multiple valid readings 
coexist independent of model confidence.

\subsection{Multi-Hypothesis Approaches}

Beam search and diverse decoding \cite{vijayakumar2016diverse} 
maintain multiple candidates during generation but ultimately select a single output. 
Mixture-of-Experts architectures \cite{shazeer2017outrageously, fedus2021switch} route 
inputs to specialized subnetworks but still produce collapsed outputs.

These approaches treat multiplicity as a means to better single outputs, not as a 
representational end state. NRR inverts this relationship: non-collapse is the goal, 
with singular output produced through non-destructive projection when required.

\subsection{Ambiguity in NLP}

Word sense disambiguation \cite{navigli2009word} and coreference resolution 
\cite{lee2017end} address specific ambiguity types but assume disambiguation is 
always desirable. Pragmatic inference models \cite{goodman2016pragmatic} reason about 
speaker intent but still converge to single interpretations.

\subsection{Relation to NRR Framework}

This paper builds directly on NRR-Core \cite{saito2025nrr}. That work established 
the state space formalism and demonstrated entropy preservation through functional verification (NRR-lite achieving $H = 0.91$ bits vs.\ baseline $H = 0.15$ bits). 
NRR defines eight operators 
($\sigma, \alpha, \rho, \iota, \delta, \tau, \kappa, \pi$) for manipulating non-collapsing 
states (see Appendix~\ref{app:operators} for summary).

This paper fills the gap between text and state space: without a defined $\phi$, 
the NRR operators have no input to operate on. We provide that input transformation.

%==============================================================================
% SECTION 3: FORMAL FRAMEWORK
%==============================================================================
\section{Formal Framework}
\label{sec:framework}

\subsection{Preliminary Definitions}

\begin{definition}[Text Space]
Let $\mathcal{T}$ denote the space of natural language texts, where each 
$T \in \mathcal{T}$ is a sequence of tokens $(t_1, t_2, \ldots, t_n)$.
\end{definition}

\begin{definition}[Semantic State Space]
Following \cite{saito2025nrr}, a \textit{semantic state space} is a structure 
$\mathcal{S} = (V, C, W, M, \preceq)$ where:
\begin{itemize}
    \item $V \subseteq \mathbb{R}^d$ is a set of semantic vector representations
    \item $C$ is a set of context identifiers
    \item $W: V \times C \to [0,1]$ is an activation weight function
    \item $M$ is a set of metadata flags (including conflict markers)
    \item $\preceq$ is a partial order on $V$ (subsumption relation)
\end{itemize}
A state instance is a set $S = \{(v_i, c_i, w_i, m_i)\}_{i=1}^{n}$ drawn from this space.
Intuitively, a state instance corresponds to a \textit{superposition} of multiple 
interpretations, each tagged by its context, weight, and metadata---analogous to 
maintaining multiple hypotheses in parallel rather than committing to one.
\end{definition}

\begin{definition}[Interpretation]
An \textit{interpretation} of text $T$ is a tuple $\iota = (v, c, w, m)$ where:
\begin{itemize}
    \item $v \in V$ is the semantic vector encoding one possible meaning
    \item $c \in C$ identifies the context under which this interpretation holds
    \item $w \in [0,1]$ is the initial activation weight
    \item $m \in M$ contains metadata (conflict flags, source markers, etc.)
\end{itemize}
\end{definition}

\subsection{The Text-to-State Mapping}

\begin{definition}[Text-to-State Mapping]
The mapping $\phi: \mathcal{T} \to \mathcal{S}$ transforms input text $T$ 
to a state space instance:
\begin{equation}
\phi(T) = \{(v_i, c_i, w_i, m_i) \mid i \in \mathcal{I}(T)\}
\end{equation}
where $\mathcal{I}(T)$ is the \textit{interpretation index set} extracted from $T$.
\end{definition}

The mapping $\phi$ decomposes into three sequential operations:
\begin{equation}
\phi = \psi_{\text{state}} \circ \psi_{\text{interp}} \circ \psi_{\text{conflict}}
\end{equation}
where:
\begin{enumerate}
    \item $\psi_{\text{conflict}}: \mathcal{T} \to \mathcal{T} \times \{0,1\}^k$ 
          detects conflict markers
    \item $\psi_{\text{interp}}: \mathcal{T} \times \{0,1\}^k \to \mathcal{I}$ 
          extracts interpretations
    \item $\psi_{\text{state}}: \mathcal{I} \to \mathcal{S}$ 
          constructs the state space
\end{enumerate}

\subsection{Stage 1: Conflict Detection}

The conflict detection stage identifies linguistic markers indicating 
multiple coexisting interpretations.

\begin{definition}[Conflict Markers]
A \textit{conflict marker set} $\mathcal{M}_{\text{conf}}$ is a collection of 
linguistic patterns indicating interpretive multiplicity:
\begin{equation}
\mathcal{M}_{\text{conf}} = \mathcal{M}_{\text{explicit}} \cup \mathcal{M}_{\text{implicit}} \cup \mathcal{M}_{\text{structural}}
\end{equation}
where:
\begin{itemize}
    \item $\mathcal{M}_{\text{explicit}}$: Explicit contradiction markers 
          (e.g., ``but'', ``however'', ``on the other hand'', ``yet'')
    \item $\mathcal{M}_{\text{implicit}}$: Hedging and uncertainty markers 
          (e.g., ``maybe'', ``perhaps'', ``might'', ``I think'')
    \item $\mathcal{M}_{\text{structural}}$: Structural ambiguity indicators 
          (e.g., ``both X and Y'', ``either... or'', coordination ambiguity)
\end{itemize}
The marker set extends to multilingual contexts; for Japanese, corresponding 
markers include adversatives (\textit{kedo}, \textit{demo}, 
\textit{shikashi}), hedging expressions (\textit{kamoshirenai}), 
and epistemic markers (\textit{to omou}). See Appendix for the complete taxonomy.
\end{definition}

\begin{definition}[Conflict Detection Function]
The conflict detection function $\psi_{\text{conflict}}$ returns:
\begin{equation}
\psi_{\text{conflict}}(T) = (T, \mathbf{f})
\end{equation}
where $\mathbf{f} = (f_1, f_2, \ldots, f_k) \in \{0,1\}^k$ is a binary feature 
vector indicating presence of each marker type.
\end{definition}

\subsection{Stage 2: Interpretation Extraction}

Interpretation extraction transforms text into a set of distinct meaning 
representations using a hybrid approach.

\begin{definition}[Hybrid Extraction]
The interpretation extraction function combines two mechanisms:
\begin{equation}
\psi_{\text{interp}}(T, \mathbf{f}) = \text{Merge}(\psi_{\text{rule}}(T, \mathbf{f}), \psi_{\text{LLM}}(T, \mathbf{f}))
\end{equation}
\end{definition}

\paragraph{Rule-Based Extraction.}
For texts with detected conflict markers ($\|\mathbf{f}\|_1 > 0$), 
rule-based extraction segments text at conflict boundaries:
\begin{equation}
\psi_{\text{rule}}(T, \mathbf{f}) = \{(s_j, c_j) \mid j \in J(T, \mathbf{f})\}
\end{equation}
where $J(T, \mathbf{f})$ indexes segments delimited by conflict markers, 
$s_j$ is the $j$-th segment, and $c_j$ is the context label derived from 
marker type (e.g., ``pre-adversative'', ``post-adversative'', ``hedge-scope'').

\paragraph{LLM-Based Extraction.}
For complex or implicit ambiguity, LLM-based extraction prompts a language 
model to enumerate interpretations:
\begin{equation}
\psi_{\text{LLM}}(T, \mathbf{f}) = \text{LLM}_{\theta}(\text{Prompt}_{\text{interp}}(T, \mathbf{f}))
\end{equation}
where $\text{Prompt}_{\text{interp}}$ is a structured prompt requesting 
exhaustive interpretation enumeration.

\paragraph{Merge Operation.}
The merge function removes duplicates via semantic similarity:
\begin{equation}
\text{Merge}(I_1, I_2) = I_1 \cup \{i \in I_2 \mid \forall j \in I_1: \text{sim}(i,j) < \tau\}
\end{equation}
where $\text{sim}(i, j)$ is cosine similarity computed over a sentence-level 
embedding space (e.g., Sentence-BERT \cite{reimers2019sentencebert}), 
and $\tau \in (0,1)$ is a deduplication threshold (typically $\tau = 0.85$).

\subsection{Stage 3: State Construction}

\begin{definition}[State Construction]
Given interpretations $\mathcal{I} = \{(\text{interp}_i, \text{ctx}_i, \text{conf}_i)\}$, 
the state construction function produces:
\begin{equation}
\psi_{\text{state}}(\mathcal{I}) = \{(v_i, c_i, w_i, m_i)\}_{i=1}^{|\mathcal{I}|}
\end{equation}
where:
\begin{align}
v_i &= \text{Embed}(\text{interp}_i) \in \mathbb{R}^d \\
c_i &= \text{ContextEncode}(\text{ctx}_i) \in C \\
w_i &= \text{conf}_i \cdot (1 + \beta \cdot \mathbf{1}[\text{conflict}]) \\
m_i &= \{\text{source}: \text{rule/LLM}, \text{conflict}: \mathbf{f}\}
\end{align}
\end{definition}

The weight adjustment factor $\beta > 0$ increases activation for 
interpretations from conflicting contexts, reflecting the NRR principle 
that conflict indicates information density.

\subsection{Information-Theoretic Properties}

\begin{definition}[State Entropy]
For a state $S = \{(v_i, c_i, w_i, m_i)\}_{i=1}^{n}$, the \textit{state entropy} 
is the Shannon entropy of the normalized weight distribution:
\begin{equation}
H(S) = -\sum_{i=1}^{n} p_i \log_2 p_i, \quad \text{where } p_i = \frac{w_i}{\sum_j w_j}
\end{equation}
Normalization is applied solely for entropy computation; the weights $w_i$ 
themselves remain unnormalized in the state representation.
\end{definition}

\begin{theorem}[Non-Collapse of $\phi$]
\label{thm:noncollapse}
For any text $T$ with $|\mathcal{I}(T)| > 1$ distinct extractable interpretations, 
the mapping $\phi$ produces a state $S$ such that:
\begin{enumerate}
    \item \textbf{(Structural non-collapse)} $|S| \geq 2$, i.e., at least two 
          interpretations are preserved in the state space.
    \item \textbf{(Entropy preservation)} The state entropy satisfies
          $H(S) > H_{\text{baseline}}(T)$
          where $H_{\text{baseline}}(T) \approx 0$ is the entropy of a 
          collapse-based model that commits to a single interpretation.
\end{enumerate}
\end{theorem}

\begin{proof}
\textbf{(1)} By construction, $\psi_{\text{interp}}$ extracts at least two 
interpretations when conflict markers are detected or when LLM enumeration 
returns multiple candidates. The merge operation removes only near-duplicates, 
preserving distinct interpretations.

\textbf{(2)} For collapse-based models, $p^* = 1$ for the selected interpretation, 
yielding $H_{\text{baseline}} = 0$. For $\phi$, with $|S| \geq 2$ and all $w_i > 0$, 
the distribution has support on multiple elements, guaranteeing $H(S) > 0$.
\end{proof}

\begin{remark}
The theorem establishes a \textit{relative} guarantee: $\phi$ preserves 
more information than collapse-based alternatives. The absolute entropy 
depends on extraction quality and weight calibration, addressed empirically 
in Section~\ref{sec:experiments}.
\end{remark}

%==============================================================================
% SECTION 4: ALGORITHM
%==============================================================================
\section{Algorithm and Implementation}
\label{sec:algorithm}

\subsection{Text-to-State Mapping Algorithm}

\begin{algorithm}[h]
\caption{Text-to-State Mapping ($\phi$)}
\label{alg:phi}
\begin{algorithmic}[1]
\REQUIRE Text $T$, embedding function Embed, LLM $\mathcal{L}_\theta$
\ENSURE State $S = \{(v_i, c_i, w_i, m_i)\}$

\STATE \textbf{// Stage 1: Conflict Detection}
\STATE $\mathbf{f} \gets \text{DetectConflictMarkers}(T)$
\STATE $\text{has\_conflict} \gets (\|\mathbf{f}\|_1 > 0)$

\STATE \textbf{// Stage 2: Interpretation Extraction}
\STATE $I_{\text{rule}} \gets \emptyset$
\IF{$\text{has\_conflict}$}
    \STATE $I_{\text{rule}} \gets \text{SegmentAtMarkers}(T, \mathbf{f})$
\ENDIF
\STATE $I_{\text{LLM}} \gets \mathcal{L}_\theta(\text{Prompt}_{\text{interp}}(T, \mathbf{f}))$
\STATE $I \gets \text{Merge}(I_{\text{rule}}, I_{\text{LLM}}, \tau)$

\STATE \textbf{// Stage 3: State Construction}
\STATE $S \gets \emptyset$
\FOR{$(\text{interp}, \text{ctx}, \text{conf}) \in I$}
    \STATE $v \gets \text{Embed}(\text{interp})$
    \STATE $c \gets \text{ContextEncode}(\text{ctx})$
    \STATE $w \gets \text{conf} \times (1 + \beta \cdot \mathbf{1}[\text{has\_conflict}])$
    \STATE $m \gets \{\text{conflict}: \mathbf{f}, \text{source}: \text{GetSource}(\text{interp})\}$
    \STATE $S \gets S \cup \{(v, c, w, m)\}$
\ENDFOR

\RETURN $S$
\end{algorithmic}
\end{algorithm}

\subsection{NRR Processing Pipeline}

The mapping $\phi$ feeds into the NRR operator pipeline (Appendix~\ref{app:operators}):

\begin{algorithm}[h]
\caption{NRR Processing Pipeline}
\label{alg:pipeline}
\begin{algorithmic}[1]
\REQUIRE Text $T$, previous state $S_{\text{prev}}$ (or $\emptyset$)
\ENSURE Processed state $S'$, output $o$

\STATE $S_{\text{new}} \gets \phi(T)$
\STATE $S_1 \gets \sigma(S_{\text{new}})$ \COMMENT{Strip biases}
\STATE $S_2 \gets \rho(S_1)$ \COMMENT{Position in context}
\STATE $S_3 \gets \delta(S_2, \lambda)$ \COMMENT{Dampen convergence}
\STATE $S_4 \gets \kappa(S_3, S_{\text{prev}})$ \COMMENT{Integrate with history (CPP)}
\STATE $S' \gets \pi(S_4, S_{\text{prev}})$ \COMMENT{Apply temporal decay to historical interpretations}
\STATE $o \gets \Pi(S')$ \COMMENT{Non-destructive projection}

\RETURN $(S', o)$
\end{algorithmic}
\end{algorithm}

\subsection{Computational Complexity}

\begin{itemize}
    \item \textbf{Conflict detection}: $O(|T| \times |\mathcal{M}|)$ where $|\mathcal{M}|$ 
          is the marker vocabulary size
    \item \textbf{Rule-based extraction}: $O(|T|)$ for segmentation
    \item \textbf{LLM-based extraction}: Dominated by LLM inference cost
    \item \textbf{State construction}: $O(|\mathcal{I}| \times d)$ for embedding
    \item \textbf{Merge deduplication}: $O(|\mathcal{I}|^2)$ for pairwise similarity
\end{itemize}

For typical inputs ($|T| < 100$ tokens, $|\mathcal{I}| < 10$ interpretations), 
the overhead is negligible compared to LLM inference.

%==============================================================================
% SECTION 5: EXPERIMENTS
%==============================================================================
\section{Experimental Validation}
\label{sec:experiments}

\subsection{Research Questions}

\begin{itemize}
    \item \textbf{RQ1}: Does $\phi$ preserve interpretive multiplicity for ambiguous inputs?
    \item \textbf{RQ2}: Which ambiguity categories are captured by rule-based vs. LLM-based extraction?
    \item \textbf{RQ3}: Does the framework generalize across languages (English, Japanese)?
    \item \textbf{RQ4}: How consistent are results across different LLMs (ChatGPT, Gemini, Claude)?
\end{itemize}

\subsection{Test Set}

We constructed a test set of 68 ambiguous sentences. For rule-based extraction 
(adversative, hedging), we include both English and Japanese sentences to demonstrate 
cross-lingual portability of $\psi_{\text{conflict}}$. For LLM-based extraction 
(epistemic, lexical, structural), we use English only to isolate the contribution 
of our framework from the multilingual capabilities of the underlying LLMs.

\begin{table}[h]
\centering
\begin{tabular}{lcccc}
\toprule
\textbf{Category} & \textbf{Total} & \textbf{EN} & \textbf{JP} & \textbf{Method} \\
\midrule
Adversative & 20 & 10 & 10 & Rule-based \\
Hedging & 20 & 10 & 10 & Rule-based \\
Epistemic & 8 & 8 & -- & LLM-based \\
Lexical & 10 & 10 & -- & LLM-based \\
Structural & 10 & 10 & -- & LLM-based \\
\midrule
\textbf{Total} & \textbf{68} & \textbf{48} & \textbf{20} & \\
\bottomrule
\end{tabular}
\caption{Test set composition. Japanese sentences are included only for rule-based 
categories to demonstrate cross-lingual portability of conflict detection.}
\label{tab:testset}
\end{table}

\begin{figure}[ht]
\centering
\includegraphics[width=0.75\linewidth]{figure1.png}
\caption{Test set composition across five ambiguity categories (68 sentences total). 
Rule-based extraction targets adversative and hedging categories with both English 
and Japanese sentences. LLM-based extraction targets epistemic, lexical, and 
structural categories with English sentences only.}
\label{fig:testset}
\end{figure}

\textbf{Adversative} sentences contain explicit contradiction markers (``but'', ``however'', 
Japanese \textit{kedo}, \textit{demo}). Example: ``I want to quit my job, but I also don't want to quit.''

\textbf{Hedging} sentences contain uncertainty markers (``maybe'', ``perhaps'', 
Japanese \textit{kamoshirenai}). Example: ``Maybe I should apply for that position.''

\textbf{Epistemic} sentences contain belief markers (``I think'', ``I believe''). 
Example: ``I think I made the right choice.''

\textbf{Lexical ambiguity} sentences contain polysemous words. 
Example: ``I saw her duck.''

\textbf{Structural ambiguity} sentences have multiple parse trees. 
Example: ``I shot an elephant in my pajamas.''

\subsection{Metrics}

\begin{itemize}
    \item \textbf{State Size} $|S|$: Number of interpretations in the state space
    \item \textbf{State Entropy} $H(S)$: Shannon entropy of the weight distribution
    \item \textbf{Conflict Detection Rate}: Proportion of sentences where markers were detected
\end{itemize}

\noindent Note that $H_{\max} = \log_2 |S|$ depends on the number of interpretations; $H_{\max} = 1.0$ bit applies only to binary ($|S|=2$) states. States with $|S| > 2$ can achieve $H > 1.0$ bits.

\subsection{Results: Rule-Based Extraction}

We first evaluate rule-based extraction alone. Table~\ref{tab:results-rule} shows 
that rule-based methods effectively capture adversative and hedging patterns 
($H \approx 1.0$) but fail on epistemic, lexical, and structural ambiguity ($H = 0$).

\begin{table}[h]
\centering
\begin{tabular}{lccc}
\toprule
\textbf{Category} & \textbf{$|S|$} & \textbf{$H(S)$} & \textbf{Method} \\
\midrule
Adversative & 2.10 & 1.037 & Rule-based \\
Hedging & 2.05 & 1.002 & Rule-based \\
Epistemic & 1.00 & 0.000 & Rule-based \\
Lexical & 1.00 & 0.000 & Rule-based \\
Structural & 1.00 & 0.000 & Rule-based \\
\bottomrule
\end{tabular}
\caption{Rule-based extraction results. Epistemic, lexical, and structural 
categories require LLM-based extraction.}
\label{tab:results-rule}
\end{table}

\noindent Note that Theorem~\ref{thm:noncollapse} requires $|\mathcal{I}(T)| > 1$ 
\textit{extractable} interpretations. For epistemic, lexical, and structural 
categories, rule-based methods cannot extract multiple interpretations 
($|\mathcal{I}| = 1$), so the theorem's precondition is not met. The $H = 0$ 
results above are not counterexamples but rather motivate the hybrid $\phi$ 
that combines rule-based and LLM-based extraction.

\subsection{Results: LLM-Based Extraction}

To address the limitations of rule-based extraction, we evaluated LLM-based 
interpretation extraction using three models: ChatGPT, Gemini, and Claude.\footnote{All 
experiments used the free tier of each service's web interface (January 2026). 
Specific version numbers are not displayed in free-tier interfaces; 
the models used were those available to free-tier users at the time 
of experimentation.} 
Each model was prompted to enumerate all possible interpretations for 28 English 
sentences (8 epistemic + 10 lexical + 10 structural).

\begin{table}[h]
\centering
\begin{tabular}{lcccc}
\toprule
\textbf{Category} & \textbf{ChatGPT} & \textbf{Gemini} & \textbf{Claude} & \textbf{Mean} \\
\midrule
Epistemic $|S|$ & 3.00 & 3.00 & 3.75 & 3.25 \\
Epistemic $H(S)$ & 1.577 & 1.558 & 1.885 & 1.673 \\
\midrule
Lexical $|S|$ & 2.00 & 2.30 & 2.20 & 2.17 \\
Lexical $H(S)$ & 0.990 & 1.024 & 1.008 & 1.007 \\
\midrule
Structural $|S|$ & 2.20 & 2.10 & 2.10 & 2.13 \\
Structural $H(S)$ & 1.056 & 0.821 & 1.027 & 0.968 \\
\bottomrule
\end{tabular}
\caption{LLM-based extraction results (English only) across three models. All categories 
achieve $H > 0$, with epistemic showing highest entropy due to multiple 
interpretive layers (assertion vs. hedge vs. self-justification).}
\label{tab:results-llm}
\end{table}

\begin{figure}[ht]
\centering
\includegraphics[width=0.85\linewidth]{figure2.png}
\caption{LLM-based extraction results across three models (ChatGPT, Gemini, Claude) 
for English sentences. The dashed line indicates $H_{\max} = 1.0$ for binary 
interpretations. All models achieve $H > 0$ across all categories, with epistemic 
showing the highest entropy due to multiple interpretive layers.}
\label{fig:llm-comparison}
\end{figure}

\paragraph{Key Findings.}

LLM-based extraction successfully recovers interpretive multiplicity for all 
categories that rule-based methods failed on:
\begin{itemize}
    \item \textbf{Epistemic}: Mean $|S| = 3.25$, $H = 1.673$ (highest entropy, 
          reflecting multiple interpretive layers)
    \item \textbf{Lexical}: Mean $|S| = 2.17$, $H = 1.007$ (captures polysemy)
    \item \textbf{Structural}: Mean $|S| = 2.13$, $H = 0.968$ (captures parse ambiguity)
\end{itemize}

Claude extracted the most interpretations on average ($|S| = 3.75$ for epistemic), 
while all three models achieved $H > 0$ for 100\% of test sentences.

\subsection{Combined Results}

Table~\ref{tab:results-combined} presents the final results combining rule-based 
extraction (for adversative and hedging, including Japanese sentences) with 
LLM-based extraction (for epistemic, lexical, and structural, English only).

\begin{table}[h]
\centering
\begin{tabular}{lcccc}
\toprule
\textbf{Category} & \textbf{N} & \textbf{$|S|$} & \textbf{$H(S)$} & \textbf{Method} \\
\midrule
Adversative & 20 & 2.10 & 1.037 & Rule (EN+JP) \\
Hedging & 20 & 2.05 & 1.002 & Rule (EN+JP) \\
Epistemic & 8 & 3.25 & 1.673 & LLM (EN) \\
Lexical & 10 & 2.17 & 1.007 & LLM (EN) \\
Structural & 10 & 2.13 & 0.968 & LLM (EN) \\
\midrule
\textbf{Overall} & \textbf{68} & \textbf{2.24} & \textbf{1.087} & Hybrid \\
\bottomrule
\end{tabular}
\caption{Combined results using hybrid extraction. All categories achieve $H > 0$, 
with overall mean entropy $H = 1.087$ bits. The overall row is computed as the 
weighted mean across all 68 sentences, where LLM-based $H$ values represent the 
three-model average for each sentence.}
\label{tab:results-combined}
\end{table}

\begin{figure}[ht]
\centering
\includegraphics[width=\linewidth]{figure3.png}
\caption{Summary of experimental results. \textbf{(A)} State entropy by category 
and extraction method. Rule-based extraction achieves $H \approx 1.0$ for 
adversative and hedging; LLM-based extraction achieves $H > 0$ for all categories. 
\textbf{(B)} Mean number of interpretations extracted per category. Epistemic 
shows highest $|S|$ due to multiple interpretive layers. \textbf{(C)} Overall 
comparison: baseline (single interpretation, $H = 0$) vs. rule-based ($H = 1.019$) 
vs. LLM-based ($H = 1.183$) vs. combined ($H = 1.087$).}
\label{fig:results-summary}
\end{figure}

\subsection{Research Question Answers}

\textbf{(RQ1)} Yes. The mapping $\phi$ preserves interpretive multiplicity: 
mean $H = 1.087$ bits across all 68 sentences, compared to $H = 0$ for 
collapse-based baselines.

\textbf{(RQ2)} Rule-based extraction captures explicit markers (adversative, hedging) 
with $H \approx 1.0$. LLM-based extraction is required for implicit ambiguity 
(epistemic, lexical, structural), achieving $H = 0.97$--$1.67$.

\textbf{(RQ3)} The rule-based conflict detector processes Japanese markers 
(\textit{kedo}, \textit{demo}, \textit{kamoshirenai}) equivalently to English, 
demonstrating cross-lingual portability of $\psi_{\text{conflict}}$.

\textbf{(RQ4)} All three LLMs (ChatGPT, Gemini, Claude) achieve $H > 0$ for 100\% of 
English test sentences. Claude extracts the most interpretations (mean $|S| = 3.75$ 
for epistemic), while Gemini is more conservative ($|S| = 3.00$). Despite variation 
in $|S|$, all models successfully preserve interpretive multiplicity.

\subsection{Limitations}

While the experimental results validate the framework, several limitations remain:

\begin{itemize}
    \item \textbf{Test set size}: 68 sentences across 5 categories provides 
          initial validation but larger-scale evaluation is needed.
    \item \textbf{LLM variability}: Different models extract different numbers 
          of interpretations (Claude: 3.75, Gemini: 3.00 for epistemic), suggesting 
          sensitivity to model choice.
    \item \textbf{Human evaluation}: We measured entropy but did not evaluate 
          whether extracted interpretations align with human judgments.
    \item \textbf{Weight calibration}: Confidence weights from LLMs may not 
          accurately reflect interpretation plausibility.
    \item \textbf{Cross-lingual scope}: We demonstrate Japanese support only for 
          rule-based extraction; full multilingual evaluation requires further work.
\end{itemize}

\noindent\textbf{Note on LLM role:} LLMs serve as convenient sources of human-like interpretation enumeration; the theoretical claims of this paper concern the structure of the resulting states, not the capabilities of the underlying models. The $\phi$ mapping framework is model-agnostic and could be instantiated with any interpretation source.

%==============================================================================
% SECTION 6: APPLICATION
%==============================================================================
\section{Illustrative Application: Psychological Support}
\label{sec:application}

We briefly illustrate how $\phi$ applies to psychological support contexts, 
where ambivalence is common and premature resolution may be counterproductive.

\subsection{Motivation}

In therapeutic contexts, statements like ``I love them, but being with them hurts'' 
express genuine ambivalence that clients benefit from exploring rather than resolving. 
Standard LLMs tend to:
\begin{itemize}
    \item Diagnose the ambivalence as a ``problem''
    \item Offer resolution strategies (pros/cons lists, decision frameworks)
    \item Select one pole as primary
\end{itemize}

With $\phi$, the ambivalent statement maps to a state with two interpretations:
\begin{align*}
S = \{&(\text{``I love them''}, \text{pre-adv}, 0.96, \{\text{conflict}: \text{True}\}), \\
      &(\text{``being with them hurts''}, \text{post-adv}, 0.96, \{\text{conflict}: \text{True}\})\}
\end{align*}

Both interpretations are preserved with equal weight, enabling responses that 
acknowledge the coexistence rather than forcing resolution.

\subsection{Limitations}

This application is \textbf{illustrative, not validated}. Whether NRR-based systems 
produce therapeutically beneficial outcomes requires:
\begin{itemize}
    \item Clinical trials with appropriate ethical oversight
    \item Comparison with established therapeutic approaches
    \item Long-term outcome measurement
\end{itemize}

NRR is a computational architecture, not a therapeutic intervention.

%==============================================================================
% SECTION 7: DISCUSSION
%==============================================================================
\section{Discussion}
\label{sec:discussion}

\subsection{Implications for LLM Architecture}

Natural language is inherently underspecified: identical lexical forms do not 
guarantee identical referential states due to perspectival variation, 
temporal--spatial indexicality, and context-dependent conceptualization. 
Consequently, committing to a single semantic interpretation at inference time 
is not an information-gain event but an information-loss event. In this view, 
the role of $\phi$ is not merely to enumerate alternative readings, but to 
formalize a separation between the factual layer (what was expressed) and the 
interpretive layer (what it could plausibly denote), allowing systems to defer 
semantic collapse until contextual constraints warrant resolution.

The text-to-state mapping demonstrates that early semantic commitment is a 
\textit{design choice}, not an architectural necessity. Systems can:
\begin{enumerate}
    \item Detect interpretive multiplicity at input
    \item Maintain multiple interpretations through processing
    \item Defer collapse until external output is required
    \item Preserve internal state after output (non-destructive projection)
\end{enumerate}

This has implications for dialogue systems, where context evolves across turns 
and early commitments may prove incorrect.

\subsection{Distinction from Prompt-Based Enumeration}

A natural question arises: if LLMs can enumerate multiple interpretations when 
prompted, why is $\phi$ necessary? Note that prompting an LLM to enumerate 
interpretations results only in a textual list, not in a persistent or manipulable 
state representation. The model generates these interpretations sequentially and 
does not maintain them as simultaneously active hypotheses. In contrast, $\phi$ 
constructs an explicit state $S$ that can be preserved and transformed by NRR 
operators across dialogue turns. The distinction is between \textit{generating} 
ambiguity (textual enumeration) and \textit{maintaining} ambiguity (state persistence).

\subsection{Limitations}

\paragraph{Marker Coverage.}
The conflict marker taxonomy is not exhaustive. Languages beyond English and 
Japanese require additional marker sets.

\paragraph{LLM Dependence.}
LLM-based extraction depends on external model availability and introduces 
non-determinism. Rule-based extraction is reproducible but limited in coverage.

\paragraph{Weight Calibration.}
Current weight assignment ($w = \text{conf} \times (1 + \beta)$) is heuristic. 
Learned weight calibration could improve entropy properties.

\paragraph{Evaluation Scope.}
The 68-sentence test set covers common ambiguity patterns but may not represent 
all real-world inputs.

\subsection{Future Work}

\begin{itemize}
    \item \textbf{Native Non-Collapsing Inference}: Integrate $\phi$ into LLM 
          architectures rather than as a preprocessing step
    \item \textbf{Learned Conflict Detection}: Train classifiers for marker 
          detection rather than pattern matching
    \item \textbf{Cross-Lingual Extension}: Develop marker taxonomies for 
          additional languages
    \item \textbf{Human Evaluation}: Assess perceived quality of non-collapsing 
          responses in user studies
\end{itemize}

%==============================================================================
% SECTION 8: CONCLUSION
%==============================================================================
\section{Conclusion}
\label{sec:conclusion}

We have presented a formal framework for text-to-state mapping ($\phi: \mathcal{T} \to \mathcal{S}$) 
that transforms natural language into a non-collapsing state space. The mapping 
decomposes into conflict detection, interpretation extraction, and state construction, 
with a hybrid approach combining rule-based and LLM-based extraction.

Experimental evaluation on 68 ambiguous sentences demonstrates that the mapping 
preserves interpretive multiplicity: mean state entropy $H = 1.087$ bits across 
all categories, compared to $H = 0$ for collapse-based baselines.

The framework provides the missing algorithmic component of Non-Resolution Reasoning: 
the transformation from text to the state space on which NRR operators act. This 
enables architectural collapse deferment in LLM inference, supporting applications 
where ambiguity preservation is valuable.

Early semantic commitment is a design choice. This paper shows how to choose otherwise.

%==============================================================================
% REFERENCES
%==============================================================================
\begin{thebibliography}{99}

\bibitem{saito2025nrr}
Saito, K. (2025).
NRR-Core: Non-resolution reasoning as a computational framework for contextual identity and ambiguity preservation.
\textit{arXiv preprint} arXiv:2512.13478.

\bibitem{reimers2019sentencebert}
Reimers, N., \& Gurevych, I. (2019).
Sentence-BERT: Sentence embeddings using Siamese BERT-networks.
\textit{EMNLP}.

\bibitem{gal2016dropout}
Gal, Y., \& Ghahramani, Z. (2016).
Dropout as a Bayesian approximation: Representing model uncertainty in deep learning.
\textit{ICML}.

\bibitem{lakshminarayanan2017simple}
Lakshminarayanan, B., Pritzel, A., \& Blundell, C. (2017).
Simple and scalable predictive uncertainty estimation using deep ensembles.
\textit{NeurIPS}.

\bibitem{kadavath2022language}
Kadavath, S., et al. (2022).
Language models (mostly) know what they know.
\textit{arXiv preprint} arXiv:2207.05221.

\bibitem{hullermeier2021aleatoric}
H{\"u}llermeier, E., \& Waegeman, W. (2021).
Aleatoric and epistemic uncertainty in machine learning: An introduction to concepts and methods.
\textit{Machine Learning}, 110(3), 457--506.

\bibitem{vijayakumar2016diverse}
Vijayakumar, A. K., et al. (2016).
Diverse beam search: Decoding diverse solutions from neural sequence models.
\textit{arXiv preprint} arXiv:1610.02424.

\bibitem{shazeer2017outrageously}
Shazeer, N., et al. (2017).
Outrageously large neural networks: The sparsely-gated mixture-of-experts layer.
\textit{ICLR}.

\bibitem{fedus2021switch}
Fedus, W., Zoph, B., \& Shazeer, N. (2021).
Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity.
\textit{JMLR}.

\bibitem{navigli2009word}
Navigli, R. (2009).
Word sense disambiguation: A survey.
\textit{ACM Computing Surveys}, 41(2), 1--69.

\bibitem{lee2017end}
Lee, K., He, L., Lewis, M., \& Zettlemoyer, L. (2017).
End-to-end neural coreference resolution.
\textit{EMNLP}.

\bibitem{goodman2016pragmatic}
Goodman, N. D., \& Frank, M. C. (2016).
Pragmatic language interpretation as probabilistic inference.
\textit{Trends in Cognitive Sciences}, 20(11), 818--829.

\end{thebibliography}

%==============================================================================
% APPENDIX
%==============================================================================
\appendix

\section{Conflict Marker Taxonomy}
\label{app:markers}

\begin{table}[h]
\centering
\small
\begin{tabular}{llll}
\toprule
\textbf{Category} & \textbf{English} & \textbf{Japanese (romanized)} & \textbf{Context Label} \\
\midrule
\multicolumn{4}{l}{\textit{Explicit Contradiction}} \\
Adversative & but, however, yet, although & \textit{kedo, demo, shikashi, daga} & \texttt{pre-adv}, \texttt{post-adv} \\
Contrastive & on the other hand, whereas & \textit{ippou de, hanmen} & \texttt{contrast-A}, \texttt{contrast-B} \\
Concessive & even though, despite & \textit{nimo kakawarazu} & \texttt{concede}, \texttt{main} \\
\midrule
\multicolumn{4}{l}{\textit{Implicit Uncertainty}} \\
Hedging & maybe, perhaps, might & \textit{kamoshirenai, tabun} & \texttt{hedge-scope} \\
Epistemic & I think, I believe, it seems & \textit{to omou, ki ga suru} & \texttt{epistemic-stance} \\
Modal & could, would, should & \textit{beki, hazu, darou} & \texttt{modal-world} \\
\midrule
\multicolumn{4}{l}{\textit{Structural Ambiguity}} \\
Coordination & both X and Y, either X or Y & \textit{mo...mo, ka...ka} & \texttt{coord-A}, \texttt{coord-B} \\
Scope & all...not, every...some & -- & \texttt{wide-scope}, \texttt{narrow-scope} \\
\bottomrule
\end{tabular}
\caption{Conflict marker taxonomy (English and Japanese)}
\label{tab:markers-full}
\end{table}

\section{LLM Prompt Template}
\label{app:prompt}

The following prompt template is used for LLM-based interpretation extraction:

\begin{verbatim}
Given the text: "[T]"

[If conflict markers detected: 
"Note: This text contains potential ambiguity markers."]

List ALL possible interpretations as distinct meanings.
For each interpretation, provide:
1. The interpretation (a clear restatement of one possible meaning)
2. The context/condition under which this interpretation holds
3. Confidence weight from 0.0 to 1.0

Format each as:
INTERP: [interpretation]
CONTEXT: [context]
CONFIDENCE: [0.0-1.0]
---
\end{verbatim}

\section{Sample Outputs}
\label{app:samples}

This appendix provides representative examples of how $\phi$ processes different 
ambiguity types. We show one example each from lexical ambiguity (LLM-based), 
structural ambiguity (LLM-based), and adversative (rule-based with Japanese).

\subsection*{Example 1: Lexical Ambiguity (LLM-based)}

\textbf{Input}: ``I saw her duck.''

\textbf{ChatGPT Output}:
\begin{verbatim}
{
  "id": "lex_en_01",
  "interpretations": [
    {
      "meaning": "I observed her pet duck (the bird).",
      "context": "noun-reading",
      "confidence": 0.5
    },
    {
      "meaning": "I saw her lower her head quickly.",
      "context": "verb-reading",
      "confidence": 0.5
    }
  ]
}
\end{verbatim}

\textbf{State constructed by $\phi$}: $|S| = 2$, $H(S) = 1.00$ bits

\subsection*{Example 2: Structural Ambiguity (LLM-based)}

\textbf{Input}: ``I shot an elephant in my pajamas.''

\textbf{ChatGPT Output}:
\begin{verbatim}
{
  "id": "str_en_01",
  "interpretations": [
    {
      "meaning": "The speaker was wearing pajamas 
                  when they shot the elephant.",
      "context": "PP attaches to subject",
      "confidence": 0.7
    },
    {
      "meaning": "The elephant was inside the speaker's 
                  pajamas when it was shot.",
      "context": "PP attaches to object",
      "confidence": 0.3
    }
  ]
}
\end{verbatim}

\textbf{State constructed by $\phi$}: $|S| = 2$, $H(S) = 0.88$ bits

\subsection*{Example 3: Japanese Adversative (Rule-based)}

\textbf{Input}: ``\textit{Yametai kedo yametakunai}'' 
(``I want to quit, but I also don't want to quit.'')

\textbf{Rule-based segmentation}: Marker ``\textit{kedo}'' detected.

\textbf{Segments extracted}:
\begin{itemize}
    \item Segment 1: ``\textit{yametai}'' (``I want to quit'') --- context: \texttt{pre-adv}
    \item Segment 2: ``\textit{yametakunai}'' (``I don't want to quit'') --- context: \texttt{post-adv}
\end{itemize}

\textbf{Weights}: Both segments receive $w = 0.5$ (equal weight for adversative).

\textbf{State constructed by $\phi$}: $|S| = 2$, $H(S) = 1.00$ bits

\vspace{1em}
\noindent These examples illustrate the difference between LLM-based extraction 
(which enumerates semantic interpretations) and rule-based extraction (which 
segments based on syntactic markers). Both approaches yield states with $H > 0$, 
preserving interpretive multiplicity.

\section{NRR Operator Design Principles and Definitions}
\label{app:operators}

This appendix details the design principles and formal definitions of the eight 
NRR operators that transform the state space $\mathcal{S}$. While the $\phi$ 
mapping (main text) handles text-to-state transformation, these operators 
perform state-to-state transformations during processing.

\subsection{Design Principles for Non-Collapsing Operators}
\label{app:principles}

Transforming NRR states risks destroying the multiplicity that NRR preserves. 
We identify four principles that operators must satisfy to maintain non-collapse. 
These principles derive from the structure of the NRR state space itself.

\subsubsection{Principle 1: Relative Structure Preservation}

\begin{principle}[Relative Structure Preservation]
\label{prin:relative}
An operator must preserve the proportional relationships between 
interpretation weights. If $w_i / w_j = r$ before the operation, 
then $w'_i / w'_j \approx r$ after.
\end{principle}

\textbf{Rationale}: Entropy depends on relative, not absolute, weight 
values. Transformations that preserve weight \textit{ratios} maintain 
the entropy structure. Note that ratio preservation is a \textit{sufficient} 
condition for non-collapse, but not strictly \textit{necessary}---operators 
such as dampening ($\delta$) preserve non-collapse by increasing entropy, 
even when ratios are not strictly preserved.

\textbf{Implementation}: Use multiplicative transformations 
(e.g., $w'_i = \lambda w_i$) or proportional adjustments 
(e.g., $w'_i = w_i - b \cdot w_i / \max w$) rather than uniform 
additive changes.

\subsubsection{Principle 2: Scale Equivariance}

\begin{principle}[Scale Equivariance]
\label{prin:scale}
An operator's effect should be independent of the absolute scale 
of weights. Scaling all weights by a constant should yield the 
same entropy change.
\end{principle}

\textbf{Rationale}: Since weights are non-normalized, absolute 
magnitudes are arbitrary. Operations should depend only on relative 
structure.

\textbf{Implementation}: Design operators such that 
$\mathcal{O}(\lambda \mathcal{S}) \sim \lambda \mathcal{O}(\mathcal{S})$ 
for scalar $\lambda > 0$. This property is verifiable analytically 
from the operator definition.

\subsubsection{Principle 3: Contradiction Non-Destruction}

\begin{principle}[Contradiction Non-Destruction]
\label{prin:contradiction}
When merging states with conflicting interpretations, preserve 
both rather than eliminating one. Contradictions are information, 
not errors.
\end{principle}

\textbf{Rationale}: This implements the Contradiction-Preservation 
Principle from NRR foundations. Contradictions are structure, not 
error; destroying them collapses information.

\textbf{Implementation}: Union with conflict tagging rather than 
replacement or selection.

\subsubsection{Principle 4: Temporal Persistence}

\begin{principle}[Temporal Persistence]
\label{prin:temporal}
Interpretations from previous states should persist (with decay) 
rather than being overwritten, enabling reactivation when context 
shifts.
\end{principle}

\textbf{Rationale}: Context may shift to favor previously dormant 
interpretations. Complete overwriting destroys information that 
may become relevant.

\textbf{Implementation}: Decayed union of current and previous states.

\subsubsection{The Information Preservation Law}

The principles converge on a single quantitative criterion.

\begin{definition}[Information Loss]
The information loss induced by operator $\mathcal{O}$ is:
\begin{equation}
L(\mathcal{O}, \mathcal{S}) = H(\mathcal{S}) - H(\mathcal{O}(\mathcal{S}))
\end{equation}
Positive $L$ indicates collapse; negative $L$ indicates information gain.
\end{definition}

\begin{definition}[Information Preservation Law]
An operator $\mathcal{O}$ satisfies the $\epsilon$-preservation law if:
\begin{equation}
H(\mathcal{O}(\mathcal{S})) \geq H(\mathcal{S}) - \epsilon
\end{equation}
for all states $\mathcal{S}$ and small threshold $\epsilon$. 
Equivalently, $L(\mathcal{O}, \mathcal{S}) \leq \epsilon$.
\end{definition}

Operators satisfying Principles 1--4 will satisfy the preservation 
law; operators violating them risk violation.

\subsection{Operator Definitions}
\label{app:operator-defs}

We define five operators that have been empirically validated to preserve 
non-collapse (\ref{app:validation}), plus three additional operators 
under consideration for future validation.

\subsubsection{Empirically Validated Operators}

The following five operators have been validated on 180 single states, 
200 contradictory pairs, and 200 temporal pairs across three LLMs.

\paragraph{Dampening ($\delta$).}
Compresses weights toward the mean, reducing dominance of any single 
interpretation:

\begin{equation}
\delta(\mathcal{S}) = \{(v_i, c_i, w_i(1-\lambda) + \bar{w}\lambda)\}
\end{equation}

where $\bar{w} = \frac{1}{n}\sum_j w_j$. Dampening does not strictly 
preserve weight ratios; rather, it satisfies the \textit{spirit} of 
Principle 1 by preventing undue suppression of minority interpretations 
and actually \textit{increases} entropy, thereby satisfying the 
$\epsilon$-preservation law. Empirically achieves 0\% collapse across 
all tested parameter settings.

\paragraph{Stripping ($\sigma$).}
Removes bias proportionally to weight magnitude:

\begin{equation}
\sigma(\mathcal{S}) = \left\{
  \left(v_i, c_i, w_i - b \cdot \frac{w_i}{\max_j w_j}\right)
\right\}
\end{equation}

Higher weights lose more in absolute terms, preserving ratios 
(Principle 1) and satisfying scale equivariance (Principle 2). 
The condition $b < \max_j w_j$ is assumed to ensure all 
transformed weights remain positive. Empirically achieves 0\% collapse.

\paragraph{Deferred Resolution ($\tau$).}
Identity during processing; resolution only at output boundary:

\begin{equation}
\tau(\mathcal{S}) = \mathcal{S}
\end{equation}

Satisfies all principles by doing nothing until output is required. 
Serves as baseline in empirical validation.

\paragraph{CPP Integration ($\kappa$).}
Implements Principle 3 (Contradiction Non-Destruction):

\begin{equation}
\kappa(\mathcal{S}, \mathcal{S}') = \mathcal{S} \cup \mathcal{S}' 
\text{ with conflict tags}
\end{equation}

Contradictory information is preserved, not eliminated. Validated on 
200 contradictory pairs with 0\% collapse.

\paragraph{Persistence ($\pi$).}
Implements Principle 4 (Temporal Persistence):

\begin{equation}
\pi(\mathcal{S}_t, \mathcal{S}_{t-1}) = \mathcal{S}_t \cup 
\{(v_i, c_i, \gamma w_i) : (v_i, c_i, w_i) \in \mathcal{S}_{t-1}\}
\end{equation}

Previous interpretations persist with decayed activation ($\gamma \in (0,1)$ 
is the decay coefficient). Validated on 
200 temporal pairs with 0\% collapse.

\subsubsection{Additional Operators Under Consideration}

The following three operators preserve weights by construction but require 
empirical validation in specific application contexts. They are included 
here as candidates for future extension of the NRR operator set.

\paragraph{Positioning ($\rho$).}
Assigns temporal coordinates to distinguish identical tokens across 
contexts:

\begin{equation}
\rho(\mathcal{S}) = \{(v_i, (c_i, t), w_i)\}
\end{equation}

Implements contextual identity tracking without affecting weights. 
Preserves entropy by construction since no weights are modified.

\paragraph{Abstraction ($\alpha$).}
Augments state with relational structure:

\begin{equation}
\alpha(\mathcal{S}) = \{(v_i, c_i, w_i, R_i)\}
\end{equation}

where $R_i = \{d(v_i, v_j) : j \neq i\}$ captures geometric relations. 
Preserves entropy by construction since no weights are modified.

\paragraph{Invariance ($\iota$).}
Marks interpretations originating from the same symbol across multiple 
contexts:

\begin{equation}
\iota(\mathcal{S}_1, \ldots, \mathcal{S}_n) = \bigcup_{j=1}^{n} \mathcal{S}_j 
\text{ with cross-context ID}
\end{equation}

where each interpretation $s_i \in \mathcal{S}_j$ receives metadata 
marking it as derived from the same underlying symbol (e.g., the word 
``bank'' appearing in financial vs.\ riverbank contexts). By construction, 
$\iota$ retains all interpretations from all input contexts: 
$|\iota(\mathcal{S}_1, \ldots, \mathcal{S}_n)| = \sum_{j} |\mathcal{S}_j|$, 
preserving or increasing entropy.

\subsubsection{Non-Destructive Projection}

For output generation:

\begin{equation}
\Pi(\mathcal{S}) = \arg\max_i w_i, \quad \mathcal{S}' = \mathcal{S}
\end{equation}

The system produces singular output while preserving internal state.
Note that $\Pi$ is an \textit{output} mechanism, not a processing 
operator; it is not subject to the design principles, since its purpose 
is precisely to select a single interpretation for external communication.

\subsection{Theoretical Properties}
\label{app:properties}

\subsubsection{Operator--Data Structure Alignment}

Different operators require different data structures for validation. 
Weight-transforming operators ($\delta$, $\sigma$, $\tau$) operate on 
individual states and are naturally validated on single states. In contrast, 
$\kappa$ (contradiction integration) and $\pi$ (temporal persistence) are 
\textit{binary} operators that take two states as input---validating 
them on single states would be meaningless, as it would fail to 
exercise their core function. Operators that neither modify weights 
nor filter interpretations ($\alpha$, $\rho$, $\iota$) preserve 
entropy by construction.

\subsubsection{Composition Behavior}

Since each principle-satisfying operator individually satisfies 
$H(\mathcal{O}(\mathcal{S})) \geq H(\mathcal{S}) - \epsilon$, 
a chain of $k$ such operators accumulates at most $k\epsilon$ 
information loss. For the operators in this appendix, this bound 
is supported analytically: $\sigma$ applies an identical multiplicative 
factor to all weights, so $\Delta H = 0$ exactly (the normalized 
distribution is invariant); $\delta$ moves weights toward the mean, 
which by the strict concavity of Shannon entropy guarantees 
$\Delta H \geq 0$; $\tau$ is the identity, so $\Delta H = 0$ trivially.

For $\epsilon = 0.1$ bits, a three-operator 
chain $\delta \circ \sigma \circ \rho$ is bounded by 
$\Delta H \leq 0.3$ bits in the worst case. In practice, since 
$\delta$ \textit{increases} entropy and $\rho$ leaves it unchanged, 
the actual cumulative loss is substantially smaller.

\subsubsection{Analytical Verification of Scale Equivariance}

Principle 2 (Scale Equivariance) requires that scaling all weights by 
a constant $c > 0$ does not change the entropy outcome. Since 
$H(\mathcal{S})$ depends only on normalized probabilities 
$p_i = w_i / \sum_j w_j$, and scaling all $w_i$ by $c$ leaves 
$p_i$ invariant, we verify that each operator commutes with scaling:

\begin{itemize}
  \item \textbf{$\sigma$ (Stripping)}: 
    $\sigma(c\mathcal{S})_i = c w_i - b \cdot c w_i / c\max w 
    = c(w_i - b \cdot w_i/\max w) = c \cdot \sigma(\mathcal{S})_i$. 
    Exact scale equivariance.

  \item \textbf{$\delta$ (Dampening)}: 
    $\delta(c\mathcal{S})_i = c w_i(1-\mu) + c\bar{w}\mu 
    = c[w_i(1-\mu) + \bar{w}\mu] = c \cdot \delta(\mathcal{S})_i$. 
    Exact scale equivariance.

  \item \textbf{$\tau$ (Identity)}: Trivially equivariant.

  \item \textbf{$\kappa$ (CPP)}: Union of sets; scaling both input states 
    by $c$ scales all weights in the output by $c$. Equivariant.

  \item \textbf{$\pi$ (Persistence)}: 
    $\pi(c\mathcal{S}_t, c\mathcal{S}_{t-1})$ scales all 
    weights (including decayed ones) by $c$. Equivariant.

  \item \textbf{$\rho$, $\alpha$, $\iota$}: These operators do not modify 
    weights, so scale equivariance is trivially satisfied.
\end{itemize}

All eight operators satisfy Principle 2 analytically.

\subsection{Operator--Principle Correspondence}
\label{app:correspondence}

Table~\ref{tab:correspondence} summarizes which principles each 
operator satisfies. P1 = Relative Structure Preservation, 
P2 = Scale Equivariance, P3 = Contradiction Non-Destruction, 
P4 = Temporal Persistence. Operators marked with \textsuperscript{\ddag} 
have been empirically validated (\ref{app:validation}).

\begin{table}[h]
\centering
\begin{tabular}{lcccc}
\toprule
\textbf{Operator} & \textbf{P1} & \textbf{P2} & \textbf{P3} & \textbf{P4} \\
\midrule
\multicolumn{5}{l}{\textit{Empirically validated:}} \\
$\delta$ (Dampening)\textsuperscript{\ddag}     & $\approx$\textsuperscript{*} & \checkmark & -- & -- \\
$\sigma$ (Stripping)\textsuperscript{\ddag}     & \checkmark & \checkmark & -- & -- \\
$\tau$ (Deferred)\textsuperscript{\ddag}        & \checkmark & \checkmark & -- & -- \\
$\kappa$ (CPP)\textsuperscript{\ddag}           & \checkmark & \checkmark & \checkmark & -- \\
$\pi$ (Persistence)\textsuperscript{\ddag}      & \checkmark & \checkmark & -- & \checkmark \\
$\rho$ (Positioning)\textsuperscript{\S}        & \checkmark & \checkmark & -- & -- \\
\midrule
\multicolumn{5}{l}{\textit{Under consideration:}} \\
$\alpha$ (Abstraction)   & \checkmark & \checkmark & -- & -- \\
$\iota$ (Invariance)     & \checkmark\textsuperscript{\dag} & \checkmark & -- & -- \\
\bottomrule
\end{tabular}
\caption{Operator--principle correspondence. 
\textsuperscript{\ddag}Empirically validated operators (\ref{app:validation}). 
\textsuperscript{\S}$\rho$ does not modify weights (only augments context metadata), 
so entropy preservation holds by construction; included in the pipeline 
(Algorithm~\ref{alg:pipeline}) without requiring empirical validation.
\textsuperscript{*}$\delta$ does not strictly preserve weight ratios (P1) 
but satisfies the $\epsilon$-preservation law by \textit{increasing} entropy. 
\textsuperscript{\dag}$\iota$ satisfies P1 by retaining all 
interpretations from all contexts.}
\label{tab:correspondence}
\end{table}

\subsection{Pipeline Composition}

The composition $\pi \circ \kappa \circ \tau \circ \delta \circ \iota 
\circ \rho \circ \alpha \circ \sigma$ defines the full NRR pipeline, 
with $\phi$ (main text) providing the input transformation from text to 
initial state. This represents the complete pipeline assuming all eight 
operators are validated; Algorithm~\ref{alg:pipeline} in the main text 
uses five operators ($\sigma$, $\rho$, $\delta$, 
$\kappa$, $\pi$), of which four are empirically validated and $\rho$ 
preserves entropy by construction (see Table~\ref{tab:correspondence}). 
The identity operator $\tau$ is empirically validated but omitted from the 
pipeline as it performs no transformation. The 
not-yet-validated $\alpha$ and $\iota$ are excluded. 
Each validated operator preserves the interpretive multiplicity established 
by $\phi$, enabling non-collapsing inference through arbitrary 
processing chains.

\subsection{Empirical Validation}
\label{app:validation}

We validate that principle-satisfying operators achieve lower collapse 
rates than principle-violating alternatives. Each operator is validated 
on the data structure appropriate to its function.

\subsubsection{Methodology}

\textbf{Data}: Three datasets were constructed using the NRR-Phi 
$\phi$ mapping procedure on a \textbf{newly constructed sentence set, 
entirely distinct from the 68-sentence test set in the main text}:

\begin{enumerate}
    \item \textbf{Single states} ($n = 180$): 60 ambiguous sentences 
          (40 epistemic, 20 lexical; English and Japanese) processed 
          by three LLMs (ChatGPT, Gemini, Claude), yielding 180 states. 
          Each state contains 2--4 interpretations with confidence weights.
    
    \item \textbf{Contradictory pairs} ($n = 200$): 150 pairs from the 
          same sentence processed by different models (capturing 
          inter-model disagreement; 50 sentences $\times$ $\binom{3}{2} = 3$ 
          model pairs, selected from the 60 sentences by excluding 
          10 with near-identical model outputs), plus 50 pairs from 
          ambiguous words in different contexts (capturing intra-word 
          polysemy).
    
    \item \textbf{Temporal pairs} ($n = 200$): 150 two-turn dialogue 
          pairs (where context evolves across turns), plus 50 
          context-evolution pairs (where the same sentence is 
          reinterpreted under shifted context).
\end{enumerate}

\textbf{Metric}: Violation rate---percentage of states where 
$H(\mathcal{S}') < H(\mathcal{S}) - \epsilon$ with $\epsilon = 0.1$ bits. 
This threshold corresponds to 10\% information loss relative to binary states 
($H_{\max} = 1.0$ bit).

\textbf{Operator--data matching}: Weight-transforming operators 
($\delta$, $\sigma$, $\tau$) are tested on single states. The integration 
operator ($\kappa$) is tested on contradictory pairs. The persistence 
operator ($\pi$) is tested on temporal pairs. This matching ensures each 
operator is validated on the data structure it is designed to process.

\textbf{Comparison}: For weight-transforming operators, we compare:
\begin{itemize}
    \item \textbf{Principle-violating}: Uniform subtraction 
          ($\delta$ v1: $w'_i = w_i - b$)
    \item \textbf{Principle-satisfying}: Proportional transformation 
          ($\delta$ v2: $w'_i = w_i(1-\lambda) + \bar{w}\lambda$; 
          $\sigma$ v2: $w'_i = w_i - b \cdot w_i/\max w$)
\end{itemize}

\textbf{Parameter sweep}: $\delta$ v1 was tested 
at three subtraction magnitudes ($b \in \{0.05, 0.10, 0.20\}$), 
$\delta$ v2 at five compression rates ($\lambda \in \{0.1, 0.2, 0.3, 0.4, 0.5\}$), 
and $\sigma$ v2 at four bias levels ($b \in \{0.05, 0.10, 0.15, 0.20\}$). 
This yields 2,740 total operator--state measurements.

\subsubsection{Results}

\begin{figure}[h]
\centering
\includegraphics[width=0.85\textwidth]{figure4.png}
\caption{Entropy change by operator type (representative parameter 
$b = 0.10$ shown for $\delta$ v1). The principle-violating 
uniform operator ($\delta$ v1, shown in red) collapses information 
in 6.1\% of cases at $b = 0.10$, falling below the 
$\Delta H = -\epsilon = -0.1$ threshold (red dashed line); other settings 
yield 1.7\% ($b = 0.05$) and 17.8\% ($b = 0.20$). 
All principle-satisfying 
operators ($\delta$ v2, $\sigma$ v2, $\tau$, $\kappa$, $\pi$, shown 
in green) achieve 0\% collapse. Operators $\kappa$ and $\pi$ 
substantially increase entropy through integration and persistence 
mechanisms.}
\label{fig:operators}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=0.95\textwidth]{figure5.png}
\caption{Analysis across ambiguity categories (epistemic, lexical). 
(A) Mean entropy by category with standard deviation error bars; both 
categories maintain high multiplicity ($H > 1.7$ bits), approaching the 
theoretical maximum for four interpretations ($H_{\max} = 2.0$ bits). 
(B) Average number of interpretations extracted per state; dashed line 
indicates minimum target ($|\mathcal{S}| \geq 2$). 
(C) Entropy increase from dampening operator ($\delta$ v2) relative to 
pre-dampening state, demonstrating consistent preservation across 
both categories.}
\label{fig:categories}
\end{figure}

Figure~\ref{fig:operators} shows entropy change by operator type. 
The principle-violating uniform operator ($\delta$ v1) collapses 
information at a rate that increases with subtraction magnitude: 
1.7\% at $b = 0.05$, 6.1\% at $b = 0.10$, and 17.8\% at 
$b = 0.20$ (32 of 180 states). In contrast, all principle-satisfying 
operators achieve \textbf{0\% collapse} across all parameter settings.

Table~\ref{tab:validation_results} presents the complete results.

\begin{table}[h]
\centering
\begin{tabular}{llrrr}
\toprule
\textbf{Operator} & \textbf{Data} & \textbf{$n$} & \textbf{Violations} & \textbf{Mean $\Delta H$} \\
\midrule
$\delta$ v1 ($b=0.05$) & single & 180 & 3 (1.7\%) & $-0.012$ \\
$\delta$ v1 ($b=0.10$) & single & 180 & 11 (6.1\%) & $-0.030$ \\
$\delta$ v1 ($b=0.20$) & single & 180 & 32 (17.8\%) & $-0.086$ \\
\midrule
$\delta$ v2 ($\lambda=0.1$) & single & 180 & 0 (0\%) & $+0.012$ \\
$\delta$ v2 ($\lambda=0.3$) & single & 180 & 0 (0\%) & $+0.031$ \\
$\delta$ v2 ($\lambda=0.5$) & single & 180 & 0 (0\%) & $+0.044$ \\
\midrule
$\sigma$ v2 ($b=0.10$) & single & 180 & 0 (0\%) & $0.000$\textsuperscript{\dag} \\
$\sigma$ v2 ($b=0.20$) & single & 180 & 0 (0\%) & $0.000$\textsuperscript{\dag} \\
\midrule
$\tau$ (identity, baseline) & single & 180 & 0 (0\%) & $0.000$ \\
\midrule
$\kappa$ (CPP) & contra.\ pairs & 200 & 0 (0\%) & $+0.881$ \\
$\pi$ (persistence) & temporal pairs & 200 & 0 (0\%) & $+0.922$ \\
\bottomrule
\end{tabular}
\caption{Experimental validation results (representative parameter values shown; 
all omitted settings also achieved 0\% violations). 
Principle-violating operators ($\delta$ v1) show increasing collapse 
rates with subtraction magnitude. All principle-satisfying operators 
achieve 0\% violations across all parameter settings tested. $\kappa$ and 
$\pi$ show large positive $\Delta H$ because they merge interpretations 
from two states, increasing multiplicity. 
\textsuperscript{\dag}$\sigma$ v2 applies an identical multiplicative 
factor $({1 - b/\max w})$ to all weights, leaving the normalized 
distribution invariant; $\Delta H = 0$ is analytically exact 
(verified computationally). Similarly, $\tau$ (identity) yields 
$\Delta H = 0$ by mathematical necessity.}
\label{tab:validation_results}
\end{table}

Figure~\ref{fig:categories} presents analysis across the two 
ambiguity categories from the single-state dataset. 
Epistemic ambiguities maintain mean entropy $H = 1.81$ bits 
(SD $= 0.49$) with an average of 3.76 interpretations per state. 
Lexical ambiguities show $H = 1.75$ bits (SD $= 0.33$) with 
3.68 interpretations. Both categories demonstrate that the 
$\phi$ mapping reliably extracts multiple distinct interpretations.

\subsubsection{Key Findings}

\begin{enumerate}
    \item \textbf{Collapse rate scales with violation magnitude}: 
          $\delta$ v1 violation rate increases monotonically from 
          1.7\% ($b=0.05$) to 17.8\% ($b=0.20$), confirming that 
          larger uniform subtractions disproportionately suppress 
          weaker interpretations.
    
    \item \textbf{Dampening increases entropy}: $\delta$ v2 shifts 
          distributions toward uniformity, raising $H$ by an average 
          of 0.03 bits at $\lambda = 0.3$. This increase is 
          analytically guaranteed by the strict concavity of Shannon 
          entropy (see Appendix~\ref{app:operators}) and confirmed 
          empirically.
    
    \item \textbf{Proportional stripping preserves structure}: 
          $\sigma$ v2 maintains entropy (mean $\Delta H \approx 0$ bits) 
          while removing bias, confirming that proportional adjustment 
          avoids the collapse induced by uniform subtraction.
    
    \item \textbf{Integration and persistence add information}: 
          $\kappa$ and $\pi$ increase $H$ by $+0.88$ and $+0.92$ bits 
          respectively, by merging interpretations from paired states.
    
    \item \textbf{Zero violations for all principle-satisfying operators}: 
          Across 180 single states and 400 pairs, no principle-satisfying 
          operator exhibited $\Delta H < -0.1$ bits under any parameter 
          setting tested.
\end{enumerate}

\section*{Acknowledgments}

The author gratefully acknowledges the support of large language models---including Claude (Anthropic), ChatGPT (OpenAI), and Gemini (Google)---for their assistance in linguistic refinement, LaTeX formatting, and general proofreading support during the preparation of this manuscript.
All concepts, arguments, and conclusions remain solely the responsibility of the author.

\end{document}
